Tags: #Tag_自然语言处理 
# Information
---
-  ACL2023

# Mainly Idea
---
- 背景：预训练模型接收了大量的数据集，数据集中可能会包含个人隐私问题，譬如名字或者地址等。 再接收到投诉后需要从预训练模型中去除此类信息。
- 现有方案：主要是对预训练模型的数据进行隐私数据去除。这样的方案比较直接，但是需要重新训练预训练模型，导致大量的资源、时间和费用的浪费。
- 所提方案：对预训练模型进行处理，并且极小的损害模型性能。

# Question
---


# Reference
---


# Attachment
---
![[2023.Knowledge Unlearning for Mitigating Privacy Risks in Language Models.pdf]]