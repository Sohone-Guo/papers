Tags: #Tag_自然语言处理 
# Information
---


# Mainly Idea
---
Only solve the mistake where the model in certain sense, "knows" the correct answer. (A wrong answer in one context, correct answer in a different context)




# Question
---
- ITI operates by shifting model activations during inference, following a set of directions across a limited number of attention heads?
- Truthfulness, helpfulness and demonstrate?
- Generation accuracy and probe accuarcy?
# Reference
---
- Kadavath et al. (2022) find language models can generate and then slf-evaluate their own ansers with high accuracy.

# Attachment
---
