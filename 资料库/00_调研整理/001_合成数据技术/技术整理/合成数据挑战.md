介绍目前合成数据所面临的问题。

## 主要问题
---
- 生成/合成的数据不太真实，可靠性较低。(生成的数据有的像真实数据，也有很多不像真实数据)
- 生成/合成的数据多样性较差，或者说有效的多样性较差。(虽然生成训练数据没有的数据，但是也远离实现场景)
- 生成/合成的数据有效性来源不太确定，突破真实困境较难。
	- 是否可以生成真实的数据集之外的数据，为重中之重。
	- 数据集以内的知识组合或者连续化，可能因为算法较弱等原因有效。

## 合成种类
---
- 将另一个数据集迁移至当前数据集
	- 虚拟场景街道的数据集→真实场景街道的数据集
- 知识蒸馏的方法：（需要考虑ChatGPT产生的数据）
- 控制生成的数据属性：提供文本规范和示例，来控制生成数据的属性。

## 主要工作
---
- [[(2021) Medically Aware GPT-3 as a Data Generator for Medical Dialogue Summarization]]
	- 主要目的：使用GPT3生成Medical dialogue summarization的数据，提高现有模型效果
	- 主要操作：①通过多个结果里面选则最好的，优化GPT3的性能。②通过GPT3生成的伪数据，再本地预训练模型进行Finetune。
	- 最终效果：210条真实数据生成的6400伪数据，约等于6400条真实数据效果。
- [[(2022) Symbolic Knowledge Distillation, from General Language MOdels to Commonsense Models]]
	- 主要目的：
	- 主要操作：
	- 最终效果：
- [[(2022) CLASP, Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing]]
	- 主要目的：
	- 主要操作：
	- 最终效果：
- [[(2022) LINGUIST, Language MOdel Instruction Tuning to Generate Annotated Utterances for Intent CLassification and Slot Tagging]]
	- 主要目的：
	- 主要操作：
	- 最终效果：
- [[(2023) SODA, Million-scale Dialogue Distillation with Social Commonsense Contextualization]]
	- 主要目的：
	- 主要操作：
	- 最终效果：
- [[(2023) Language Models are Realistic tabular Data Generators]]
	- 主要目的：
	- 主要操作：
	- 最终效果：
- [[(2023) Does Synthetic Data Generation of LLMs Help Clinical Text Mining]]
	- 主要目的：
	- 主要操作：
	- 最终效果：