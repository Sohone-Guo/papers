Tags: #Tag_多模态 #Tag_计算机视觉 
# Information
---


# Mainly Idea
---
- Pretrain:
	- ![[Pasted image 20230720230536.png]]
- Finetune:
	- ![[Pasted image 20230720230608.png]]
	- ![[Pasted image 20230720225458.png]]

# Question
---
- What is the token-based autoregressive models?
	-  256x256 image into 1024 tokens from  a vocabulary of 8192.
		- 参考VQ-VAE or [[(2022) Make-A-Scene, Scene-Based Text-to-Image Generation with Human Priors]]
- CML3: [[(2022) CM3, A Causal Masked Multimodal Model of The Internet]]
- Retrieval: 合成一个句子中，可以提高zero-shot
	- [[(2022) Retrieval-Augmented Multimodal Language Modeling]]
- VQ-VAE: [[(2023) Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers]]

# Reference
---


# Attachment
---
![[Scaling Autoregressive Multi-Modal Models, Pretraining and Instruction Tuning.pdf]]